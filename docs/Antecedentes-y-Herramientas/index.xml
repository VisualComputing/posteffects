<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posteffects</title><link>https://visualcomputing.github.io/posteffects/docs/Antecedentes-y-Herramientas/</link><description>Recent content on Posteffects</description><generator>Hugo -- gohugo.io</generator><language>es-co</language><atom:link href="https://visualcomputing.github.io/posteffects/docs/Antecedentes-y-Herramientas/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://visualcomputing.github.io/posteffects/docs/Antecedentes-y-Herramientas/IA-y-Efectos-de-Posprocesado-Antecedentes/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://visualcomputing.github.io/posteffects/docs/Antecedentes-y-Herramientas/IA-y-Efectos-de-Posprocesado-Antecedentes/</guid><description>La IA y los Efectos de Posprocesado. # Esta sección presenta una revisión de literatura, breve, no por omisión sino por falta de relación con la forma con la que en este proyecto se desea interactuar con los diferentes efectos. Esta lejanía no constituye un inconveniente per sé, sino es un reflejo de la actual manera de relacionar la inteligencia artificial y la computación gráfica.
(Diolazis 2022) Se desarrolla un modelo de iluminación basado en redes neuronales, capaz de predecir este efecto en las diferentes configuraciones de una escena con elementos variables (disposición de los objetos y materiales).</description></item><item><title/><link>https://visualcomputing.github.io/posteffects/docs/Antecedentes-y-Herramientas/Interacci%C3%B3n-con-Modelos-de-Lenguaje/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://visualcomputing.github.io/posteffects/docs/Antecedentes-y-Herramientas/Interacci%C3%B3n-con-Modelos-de-Lenguaje/</guid><description>Interacción con Modelos de Lenguaje. # Como fue mencionado anteriormente, los grandes modelos de lenguaje poseen la capacidad de llevar a cabo una amplia gama de tareas cuyo único factor común es casi la coherencia gramática; esto gracias a la ingente cantidad de datos con los que fueron entrenados y la abstracción del lenguaje plasmada en sus parámetros.
Mientras más específica sea la tarea que el modelo deba ejecutar, se le debe alimentar con información más puntual y entradas que entre más detalladas sean, deben tener una longitud mayor.</description></item></channel></rss>