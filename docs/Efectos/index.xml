<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posteffects</title><link>https://visualcomputing.github.io/posteffects/docs/Efectos/</link><description>Recent content on Posteffects</description><generator>Hugo -- gohugo.io</generator><language>es-co</language><atom:link href="https://visualcomputing.github.io/posteffects/docs/Efectos/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://visualcomputing.github.io/posteffects/docs/Efectos/Mapa-de-Profundidad/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://visualcomputing.github.io/posteffects/docs/Efectos/Mapa-de-Profundidad/</guid><description>Mapa de Profundidad # Un mapa de profundidad es una forma sencilla de visualizar cuán lejos se encuentran los elementos de una escena con respecto a un plano de visualización. La distancia entre dicho plano y cada punto se mapea en un canal de color cuyo valor es proporcional al de dicha magnitud
Este efecto se ilustra a continuación; ambas escenas muestran un cubo describiendo un círculo al rededor del eje Y.</description></item><item><title/><link>https://visualcomputing.github.io/posteffects/docs/Efectos/Profundidad-de-Campo/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://visualcomputing.github.io/posteffects/docs/Efectos/Profundidad-de-Campo/</guid><description>Profundidad de Campo # La profunidad de campo corresponde al área e nla que el ojo percibe un elemento con la nitidez suficiente o cuanto de la imagen es visualizable de forma nítida, si lo es en su totalidad se dice que se tiene una Profundidad de Campo Máxima.
Los objetos más cercanos a un plano de foco en la escena tendrán una nitidez mayor a los más lejanos. Solo aquellos que se encuentran en el plano poseerán un enfoque perfecto teoricamente, sin embargo el ojo brinda un rango de holgura que flexibiliza esta apreciación.</description></item><item><title/><link>https://visualcomputing.github.io/posteffects/docs/Efectos/Pixelador/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://visualcomputing.github.io/posteffects/docs/Efectos/Pixelador/</guid><description>Pixelador # El pixelado es un efecto en el que la resolución de la imagen se baja de manera intencional. Su aplicación más común se encuentra en el ocultamiento de elementos sensibles o polémicos en una escena, sin embargo en los últimos años ha sido usado frecuentemente en el sector artístico gracias a la estética PixelArt.
Con el objeto de visualizar mejor este efecto, se preparó una sencilla escena compuesta por objetos curvos en movimiento.</description></item><item><title/><link>https://visualcomputing.github.io/posteffects/docs/Efectos/Detecci%C3%B3n-de-Bordes/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://visualcomputing.github.io/posteffects/docs/Efectos/Detecci%C3%B3n-de-Bordes/</guid><description>Detección de Bordes # Se define como borde aquellos cambios en la dirección de la superficie, a los puntos en los que materiales diferentes entran en contacto, cambios abruptos en la luz o en la profundidad.
Hay ocasiones en las que es necesario encontrar dichos bordes, por ejemplo si se desea segmentar una imagen, hallar elementos puntuales o reducir el la cantidad de información con la que se entrena determinado modelo de inteligencia artificial.</description></item><item><title/><link>https://visualcomputing.github.io/posteffects/docs/Efectos/Desenfoque-Horizontal/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://visualcomputing.github.io/posteffects/docs/Efectos/Desenfoque-Horizontal/</guid><description>Desenfoque Horizontal # Los filtros de desenfoque son un efecto en el que se suaviza la textura sobre la que este se aplica, de modo que se atenúan las diferencias abruptas de color.
Existen diferentes tipos de efectos de desenfoque, sin embargo en este apartado se tratará el desenfoque horizontal, que difiere de los otros al incrementar la pérdida de detalle sobre los elementos que se encuentren a mayor distancia vertical de un horizonte dado.</description></item><item><title/><link>https://visualcomputing.github.io/posteffects/docs/Efectos/Caleidoscopio/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://visualcomputing.github.io/posteffects/docs/Efectos/Caleidoscopio/</guid><description>Caleidoscopio # «En la memoria del hombre, ninguna invención y ningún trabajo, ya sea dirigido a la imaginación o al entendimiento, jamás producirá un efecto como tal» (Comentario de Peter Mark Roget sobre el caleidoscopio).
El caleidoscopio fue inventado en 1816 por el físico David Browster. Consta de un tubo en cuyo interior hay tres espejos que forman un prisma con las caras interiores reflectantes y en cuyo extremo, encerrados entre dos láminas translúcidas, hay varios objetos de diferente color y forma que se ven multiplicados al girar el tubo.</description></item><item><title/><link>https://visualcomputing.github.io/posteffects/docs/Efectos/Ruido/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://visualcomputing.github.io/posteffects/docs/Efectos/Ruido/</guid><description>Ruido # Los algoritmos de ruido han sido una elegante forma de abordar problemas en distintas áreas, esto se debe a su capacidad para relacionarse con comportamientos caóticos o simplemente aleatorios. Han sido utilizados en la generación de terreno de forma procedural, simulación de físicas de movimiento de fluidos, texturización procedural para obtener materiales más realistas, etc.
En esta sección, se hará uso de un algoritmo generador de ruido para causar distorsiones y movimiento en una imagen determinada.</description></item><item><title/><link>https://visualcomputing.github.io/posteffects/docs/Efectos/Rayos/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://visualcomputing.github.io/posteffects/docs/Efectos/Rayos/</guid><description>Rayos # Código del Fragment Shader del efecto: # Cotidianamente no hay entornos uniformemente iluminados, la luz interactúa con los objetos de formas distintas considerando factores como su posición respecto al emisor y al observador, las propiedades intrínsecas de la onda y el material sobre el que cae. Es de este hecho que surge una de las principales aplicaciones de los shaders, los modelos de iluminación.
Con intensión de dar más realismo o vida a una escena, se aplican los modelos de iluminación.</description></item></channel></rss>