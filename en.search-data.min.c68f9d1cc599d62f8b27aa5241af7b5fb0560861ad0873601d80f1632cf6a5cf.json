[{"id":0,"href":"/posteffects/docs/Efectos/Mapa-de-Profundidad/","title":"Mapa De Profundidad","section":"Efectos","content":" Mapa de Profundidad # Un mapa de profundidad es una forma sencilla de visualizar cuán lejos se encuentran los elementos de una escena con respecto a un plano de visualización. La distancia entre dicho plano y cada punto se mapea en un canal de color cuyo valor es proporcional al de dicha magnitud\nEste efecto se ilustra a continuación; ambas escenas muestran un cubo describiendo un círculo al rededor del eje Y. La escena de la derecha muestra una aplicación del Mapa de Profundidad.\nCódigo del fragment shader del efecto: # precision highp float; // took from: https://learnopengl.com/Advanced-OpenGL/Depth-testing void main() { // gl_FragCoord.z is in the range [0..1] gl_FragColor = vec4(vec3(gl_FragCoord.z), 1.0); } Para comprender este efecto basta con estudiar esta línea:\ngl_FragColor = vec4(vec3(gl_FragCoord.z), 1.0); En otras palabras, se extrae la coordenada Z de cada fragmento, y se guarda en un vector de cuatro componentes, que representará un color sin transparencia con el que se teñirán los fragmentos corresponientes.\n"},{"id":1,"href":"/posteffects/docs/Monitor%C3%ADa-POO/Introducci%C3%B3n-a-JavaScript/","title":"Introducción a Java Script","section":"Monitoría Poo","content":" Introducción a JavaScript # Funciones # Cadenas # Objetos Literales # "},{"id":2,"href":"/posteffects/docs/Monitor%C3%ADa-POO/Introducci%C3%B3n-a-p5/","title":"Introducción a P5","section":"Monitoría Poo","content":" Introducción a p5.js # JSON # "},{"id":3,"href":"/posteffects/docs/Ap%C3%A9ndices/Apuntes-de-p5.treegl/","title":"Apuntes De P5.treegl","section":"Apéndices","content":" p5.treegl # En términos bastante generales, p5.treegl es una librería destinada tanto a la lectura y manejo de matrices en p5.js como a la automatización de parte de la linea de ensamblado del desarrollo de shaders. Este apartado se enfocará en describir y tener a la mano algunas de las herramientas que p5.treegl suministra y que son utilizadas dentro de este trabajo.\nEsta sección no pretende ser una documentación oficial de la librería, para información más precisa y detallada, diríjase al repositorio original\n"},{"id":4,"href":"/posteffects/docs/Efectos/Profundidad-de-Campo/","title":"Profundidad De Campo","section":"Efectos","content":" Profundidad de Campo # "},{"id":5,"href":"/posteffects/docs/Efectos/Pixelador/","title":"Pixelador","section":"Efectos","content":" Pixelador # El pixelado es un efecto en el que la resolución de la imagen se baja de manera intencional. Su aplicación más común se encuentra en el ocultamiento de elementos sensibles o polémicos en una escena, sin embargo en los últimos años ha sido usado frecuentemente en el sector artístico gracias a la estética PixelArt.\nCon el objeto de visualizar mejor este efecto, se preparó una sencilla escena compuesta por objetos curvos en movimiento. La estructura de estos elementos hace más notable la aparición de los pixeles, los cuales, gracias a la variación de los parámetros del lienzo, no son necesariamente cuadrados.\nCódigo del Fragment Shader del efecto: # pixelate.frag precision mediump float; uniform sampler2D tex; uniform float xPixels; uniform float yPixels; varying vec2 texcoords2; void main() { vec2 texCoords = vec2(floor(texcoords2.s * xPixels) / xPixels, floor(texcoords2.t * yPixels) / yPixels); gl_FragColor = texture2D(tex, texCoords); } El núcleo de este shader se encuentra en esta línea:\nvec2 texCoords = vec2(floor(texcoords2.s * xPixels) / xPixels, floor(texcoords2.t * yPixels) / yPixels); Obtiene nuevas coordenadas de textura, cuyas componentes están dadas por la función\n\\[s_p(s) = \\frac{\\lfloor p * s \\rfloor}{p}\\] Dónde \\(s\\) es un componente de una coordenada de textura y \\(p\\) indica la cantidad de resolución deseada para cada componente. La obtención de las nuevas coordenadas de textura se puede apreciar con ayuda de la siguiente gráfica.\nPara valores más elevados de \\(p\\) , la coordenada de salida se aproxima más a su posición original.\ngl_FragColor = texture2D(tex, texCoords); Finalmente el fragmento adquiere el color correspondiente a la nueva coordenada en la textura de entrada.\n"},{"id":6,"href":"/posteffects/docs/Efectos/Detecci%C3%B3n-de-Bordes/","title":"Detección De Bordes","section":"Efectos","content":" Detección de Bordes # Se define como borde aquellos cambios en la dirección de la superficie, a los puntos en los que materiales diferentes entran en contacto, cambios abruptos en la luz o en la profundidad.\nHay ocasiones en las que es necesario encontrar dichos bordes, por ejemplo si se desea segmentar una imagen, hallar elementos puntuales o reducir el la cantidad de información con la que se entrena determinado modelo de inteligencia artificial. Afortunadamente existen efectos como el mostrado en esta sección, capaces de transformar una escena en una representación de sus contornos.\nPara ilustrar lo anteriormente descrito, se aplica el efecto de detección de bordes sobre un conjunto de elementos coloreados y ubicados de forma aleatoria en el espacio.\nCódigo del Fragment Shader del Efecto. # edge.frag precision mediump float; uniform sampler2D tex; uniform vec2 aspect; varying vec2 texcoords2; vec2 texel = vec2(aspect.x, aspect.y); mat3 G[9]; mat3 G0 = mat3( 0.5/sqrt(2.0), 0, -0.5/sqrt(2.0), 0.5, 0, -0.5, 0.5/sqrt(2.0), 0, -0.5/sqrt(2.0) ); mat3 G1 = mat3( 0.5/sqrt(2.0), 0.5, 0.5/sqrt(2.0), 0, 0, 0, -0.5/sqrt(2.0), -0.5, -0.5/sqrt(2.0) ); mat3 G2 = mat3( 0, -0.5/sqrt(2.0), 0.5, 0.5/sqrt(2.0), 0, -0.5/sqrt(2.0), -0.5, 0.5/sqrt(2.0), 0 ); mat3 G3 = mat3( 0.5, -0.5/sqrt(2.0), 0, -0.5/sqrt(2.0), 0, 0.5/sqrt(2.0), 0, 0.5/sqrt(2.0), -0.5 ); mat3 G4 = mat3( 0, 0.5/sqrt(2.0), 0, -0.5/sqrt(2.0), 0, -0.5/sqrt(2.0), 0, 0.5/sqrt(2.0), 0); mat3 G5 = mat3( -0.5/sqrt(2.0), 0, 0.5/sqrt(2.0), 0, 0, 0, 0.5/sqrt(2.0), 0, -0.5/sqrt(2.0) ); mat3 G6 = mat3( 1.0/6.0, -1.0/3.0, 1.0/6.0, -1.0/3.0, 2.0/3.0, 1.0/3.0, 1.0/6.0, -1.0/3.0, 1.0/6.0 ); mat3 G7 = mat3( -1.0/3.0, 1.0/6.0, -1.0/3.0, 1.0/6.0, 2.0/3.0, 1.0/6.0, -1.0/3.0, 1.0/6.0, -1.0/3.0); mat3 G8 = mat3( 1.0/3.0, 1.0/3.0, 1.0/3.0, 1.0/3.0, 1.0/3.0, 1.0/3.0, 1.0/3.0, 1.0/3.0, 1.0/3.0 ); void main(void) { G[0] = G0; G[1] = G1; G[2] = G2; G[3] = G3; G[4] = G4; G[5] = G5; G[6] = G6; G[7] = G7; G[8] = G8; mat3 I; float cnv[9]; vec3 s; for (float i=0.0; i\u0026lt;3.0; i++) { for (float j=0.0; j\u0026lt;3.0; j++) { s = texture2D(tex, texcoords2.st + texel * vec2(i-1.0,j-1.0)).rgb; I[int(i)][int(j)] = length(s); } } for (int i=0; i\u0026lt;9; i++) { float dp3 = dot(G[i][0], I[0]) + dot(G[i][1], I[1]) + dot(G[i][2], I[2]); cnv[i] = dp3 * dp3; } float M = (cnv[0] + cnv[1]) + (cnv[2] + cnv[3]); float S = (cnv[4] + cnv[5]) + (cnv[6] + cnv[7]) + (cnv[8] + M); gl_FragColor = vec4(vec3(sqrt(M/S)), 1.0); } Para entender este shader, hay que empezar por analizar esta sección:\nmat3 G[9]; mat3 G0 = mat3( 0.5/sqrt(2.0), 0, -0.5/sqrt(2.0), 0.5, 0, -0.5, 0.5/sqrt(2.0), 0, -0.5/sqrt(2.0) ); mat3 G1 = mat3( 0.5/sqrt(2.0), 0.5, 0.5/sqrt(2.0), 0, 0, 0, -0.5/sqrt(2.0), -0.5, -0.5/sqrt(2.0) ); mat3 G2 = mat3( 0, -0.5/sqrt(2.0), 0.5, 0.5/sqrt(2.0), 0, -0.5/sqrt(2.0), -0.5, 0.5/sqrt(2.0), 0 ); mat3 G3 = mat3( 0.5, -0.5/sqrt(2.0), 0, -0.5/sqrt(2.0), 0, 0.5/sqrt(2.0), 0, 0.5/sqrt(2.0), -0.5 ); mat3 G4 = mat3( 0, 0.5/sqrt(2.0), 0, -0.5/sqrt(2.0), 0, -0.5/sqrt(2.0), 0, 0.5/sqrt(2.0), 0); mat3 G5 = mat3( -0.5/sqrt(2.0), 0, 0.5/sqrt(2.0), 0, 0, 0, 0.5/sqrt(2.0), 0, -0.5/sqrt(2.0) ); mat3 G6 = mat3( 1.0/6.0, -1.0/3.0, 1.0/6.0, -1.0/3.0, 2.0/3.0, 1.0/3.0, 1.0/6.0, -1.0/3.0, 1.0/6.0 ); mat3 G7 = mat3( -1.0/3.0, 1.0/6.0, -1.0/3.0, 1.0/6.0, 2.0/3.0, 1.0/6.0, -1.0/3.0, 1.0/6.0, -1.0/3.0); mat3 G8 = mat3( 1.0/3.0, 1.0/3.0, 1.0/3.0, 1.0/3.0, 1.0/3.0, 1.0/3.0, 1.0/3.0, 1.0/3.0, 1.0/3.0 ); Si se escriben en forma matemática estas variables, es posible llegar a los siguientes kernels.\n\\[G_0 = \\frac{1}{2\\sqrt{2}} \\cdot \\left[ \\begin{matrix} 1 \u0026amp; 0 \u0026amp; -1 \\\\ \\sqrt{2} \u0026amp; 0 \u0026amp; -\\sqrt{2} \\\\ 1 \u0026amp; 0 \u0026amp; -1 \\\\ \\end{matrix} \\right] \\\\ G_1 = \\frac{1}{2\\sqrt{2}} \\cdot \\left[ \\begin{matrix} 1 \u0026amp; \\sqrt{2} \u0026amp; 1 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \\\\ -1 \u0026amp; -\\sqrt{2} \u0026amp; -1 \\\\ \\end{matrix} \\right] \\\\ G_2 = \\frac{1}{2\\sqrt{2}} \\cdot \\left[ \\begin{matrix} 0 \u0026amp; -1 \u0026amp; \\sqrt{2} \\\\ 1 \u0026amp; 0 \u0026amp; -1 \\\\ -\\sqrt{2} \u0026amp; 1 \u0026amp; 0 \\\\ \\end{matrix} \\right] \\\\ G_3 = \\frac{1}{2\\sqrt{2}} \\cdot \\left[ \\begin{matrix} \\sqrt{2} \u0026amp; -1 \u0026amp; 0 \\\\ -1 \u0026amp; 0 \u0026amp; 1 \\\\ 1 \u0026amp; 0 \u0026amp; -1 \\\\ \\end{matrix} \\right] \\\\ G_4 = \\frac{1}{2\\sqrt{2}} \\cdot \\left[ \\begin{matrix} 0 \u0026amp; 1 \u0026amp; 0 \\\\ -1 \u0026amp; 0 \u0026amp; -1 \\\\ 0 \u0026amp; 1 \u0026amp; 0 \\\\ \\end{matrix} \\right] \\\\ G_5 = \\frac{1}{2\\sqrt{2}} \\cdot \\left[ \\begin{matrix} -1 \u0026amp; 0 \u0026amp; 1 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \\\\ 1 \u0026amp; 0 \u0026amp; -1 \\\\ \\end{matrix} \\right] \\\\ G_6 = \\frac{1}{6} \\cdot \\left[ \\begin{matrix} 1 \u0026amp; -2 \u0026amp; 1 \\\\ -2 \u0026amp; 4 \u0026amp; 2 \\\\ 1 \u0026amp; -2 \u0026amp; 11 \\\\ \\end{matrix} \\right] \\\\ G_7 = \\frac{1}{2\\sqrt{2}} \\cdot \\left[ \\begin{matrix} -2 \u0026amp; 1 \u0026amp; -2 \\\\ 1 \u0026amp; 4 \u0026amp; 1 \\\\ -2 \u0026amp; 1 \u0026amp; -2 \\\\ \\end{matrix} \\right] \\\\ G_8 = \\frac{1}{3} \\cdot \\left[ \\begin{matrix} 1 \u0026amp; 1 \u0026amp; 1 \\\\ 1 \u0026amp; 1 \u0026amp; 1 \\\\ 1 \u0026amp; 1 \u0026amp; 1 \\\\ \\end{matrix} \\right]\\] Aquellas son las Máscaras de Frei-Chen, las cuales constituyen una autobase bajo la cual se pueden representar todas las matrices \\( 3 \\times 3 \\) cambiando el escalar que las multiplica (Demostrasión fuera del alcance de este trabajo); por tanto son una generalización de cualquier operación de enmascaramiento.\nConvolución. # mat3 I; float cnv[9]; vec3 s; for (float i=0.0; i\u0026lt;3.0; i++) { for (float j=0.0; j\u0026lt;3.0; j++) { s = texture2D(tex, texcoords2.st + texel * vec2(i-1.0,j-1.0)).rgb; I[int(i)][int(j)] = length(s); } } En el vector s se guardan los colores de los texeles adyacentes al pixel actual, para después almacenar su brillo en la matriz I.\nfor (int i=0; i\u0026lt;9; i++) { float dp3 = dot(G[i][0], I[0]) + dot(G[i][1], I[1]) + dot(G[i][2], I[2]); cnv[i] = dp3 * dp3; } float M = (cnv[0] + cnv[1]) + (cnv[2] + cnv[3]); float S = (cnv[4] + cnv[5]) + (cnv[6] + cnv[7]) + (cnv[8] + M); Se almacenan los cuadrados de los productos punto de las filas de cada kernel y las de la matriz I en un arreglo de nueve componentes que contiene los valores de la convolución. Finalmente es cuestión de obtener una suma de los cuatro primeros valores (M) y otra de todos los elementos (S) y se utiliza la raíz del cociente de estas cantidades para definir el valor del color del fragmento, el cual está en escala de grises.\ngl_FragColor = vec4(vec3(sqrt(M/S)), 1.0); Referencias: # Detección de Bordes en una Imagen G. Madruga, Efectos de Espacio de Imagen Procesamiento de imágenes con derivadas - Detección de esquinas y bordes. "},{"id":7,"href":"/posteffects/docs/Efectos/Desenfoque-Horizontal/","title":"Desenfoque Horizontal","section":"Efectos","content":" Desenfoque Horizontal # Los filtros de desenfoque son un efecto en el que se suaviza la textura sobre la que este se aplica, de modo que se atenúan las diferencias abruptas de color.\nExisten diferentes tipos de efectos de desenfoque, sin embargo en este apartado se tratará el desenfoque horizontal, que difiere de los otros al incrementar la pérdida de detalle sobre los elementos que se encuentren a mayor distancia vertical de un horizonte dado.\nLa demostrasión de este efecto se hace sobre un conjunto de elementos aleatoriamente posicionados en el espacio, de modo que el observador pueda encontrar un objeto a diferentes alturas en la imagen y evidenciar de ese modo la forma en que el nivel de desenfoque varía.\nCódigo del Fragment Shader del efecto. # horizontal.frag precision mediump float; uniform sampler2D tDiffuse; uniform float h; uniform float r; varying vec2 texcoords2; void main() { vec2 vUv = texcoords2.st; vec4 sum = vec4( 0.0 ); float hh = h * abs( r - vUv.y ); sum += texture2D( tDiffuse, vec2( vUv.x - 4.0 * hh, vUv.y ) ) * 0.051; sum += texture2D( tDiffuse, vec2( vUv.x - 3.0 * hh, vUv.y ) ) * 0.0918; sum += texture2D( tDiffuse, vec2( vUv.x - 2.0 * hh, vUv.y ) ) * 0.12245; sum += texture2D( tDiffuse, vec2( vUv.x - 1.0 * hh, vUv.y ) ) * 0.1531; sum += texture2D( tDiffuse, vec2( vUv.x, vUv.y ) ) * 0.1633; sum += texture2D( tDiffuse, vec2( vUv.x + 1.0 * hh, vUv.y ) ) * 0.1531; sum += texture2D( tDiffuse, vec2( vUv.x + 2.0 * hh, vUv.y ) ) * 0.12245; sum += texture2D( tDiffuse, vec2( vUv.x + 3.0 * hh, vUv.y ) ) * 0.0918; sum += texture2D( tDiffuse, vec2( vUv.x + 4.0 * hh, vUv.y ) ) * 0.051; gl_FragColor = sum; } Considerando que r representa la altura del horizonte imaginario en la textura de entrada (por lo que su valor está normalizado) y h el nivel de desenfoque, es más sencillo intuir el funcionamiento del shader a partir de esta linea:\nfloat hh = h * abs( r - vUv.y ); Es decir que hh es la distancia horizontal entre los pixeles cuya diferencia se atenuará posteriormente. esta cantidad es proporcional a la distancia entre la vertical de la coordenada actual de textura y el horizonte.\nComo es usual, este suavizado también depende de una convolución entre los valores de los pixeles y determinado kernel. En este caso, como los pixeles están siendo seleccionados unicamente en sentido horizontal, la máscara debe ser también un vector y el resultado de la operación (el nuevo color del fragmento) no es más que el producto punto entre estos elementos\n\\[sum = (u - 4hh, u - 3hh, u - 2hh, u - hh, u, u \u0026#43; hh, u \u0026#43;2hh , u \u0026#43; 3hh, u \u0026#43; 4hh) \\cdot \\left[ \\begin{matrix} 0.051 \\\\ 0.0918 \\\\ 0.12245 \\\\ 0.1531 \\\\ 0.1633 \\\\ 0.1531 \\\\ 0.12245 \\\\ 0.0918 \\\\ 0.051 \\end{matrix} \\right]\\] Dónde \\(u\\) es el componente horizontal de la coordenada de textura actual.\nsum += texture2D( tDiffuse, vec2( vUv.x - 4.0 * hh, vUv.y ) ) * 0.051; sum += texture2D( tDiffuse, vec2( vUv.x - 3.0 * hh, vUv.y ) ) * 0.0918; sum += texture2D( tDiffuse, vec2( vUv.x - 2.0 * hh, vUv.y ) ) * 0.12245; sum += texture2D( tDiffuse, vec2( vUv.x - 1.0 * hh, vUv.y ) ) * 0.1531; sum += texture2D( tDiffuse, vec2( vUv.x, vUv.y ) ) * 0.1633; sum += texture2D( tDiffuse, vec2( vUv.x + 1.0 * hh, vUv.y ) ) * 0.1531; sum += texture2D( tDiffuse, vec2( vUv.x + 2.0 * hh, vUv.y ) ) * 0.12245; sum += texture2D( tDiffuse, vec2( vUv.x + 3.0 * hh, vUv.y ) ) * 0.0918; sum += texture2D( tDiffuse, vec2( vUv.x + 4.0 * hh, vUv.y ) ) * 0.051; gl_FragColor = sum; Referencias: # OpenGL - Programming Guide, Chapter 9: Texture Mapping Parte III: La Referencia de Funciones del GIMP, Capítulo 14, Filtros "},{"id":8,"href":"/posteffects/docs/Efectos/Caleidoscopio/","title":"Caleidoscopio","section":"Efectos","content":" Caleidoscopio # «En la memoria del hombre, ninguna invención y ningún trabajo, ya sea dirigido a la imaginación o al entendimiento, jamás producirá un efecto como tal» (Comentario de Peter Mark Roget sobre el caleidoscopio).\nEl caleidoscopio fue inventado en 1816 por el físico David Browster. Consta de un tubo en cuyo interior hay tres espejos que forman un prisma con las caras interiores reflectantes y en cuyo extremo, encerrados entre dos láminas translúcidas, hay varios objetos de diferente color y forma que se ven multiplicados al girar el tubo.\nFigura 1: Esquema de un calidoscopio hecho artesanalmente. El efecto de un caleidoscopio puede parecer complejo, sin embargo es de sencilla implementación; la escena a continuación es prueba de ello. Los diversos objetos que conforman la imagen se verán reflejados tantas veces como la barra de configuración lo permita\nCódigo del Fragment Shader del efecto: # caleido.frag precision mediump float; uniform sampler2D texture; uniform float segments; varying vec2 texcoords2; void main() { vec2 coord = 2.0 * texcoords2 - 1.0; float r = length(coord); float theta = atan(coord.y, abs(coord.x)); theta *= segments; coord = vec2(r * cos(theta), r * sin(theta)); coord = (coord + 1.0) / 2.0; gl_FragColor = texture2D(texture, coord); } Como primer paso fundamental, se ejecuta un remapeo de las coordenadas de textura, considerando que lo que se desea es obtener reflejos usando radios como eje de simetría.\nvec2 coord = 2.0 * texcoords2 - 1.0; Ahora el punto \\((0,0) \\) se convirtió en el centro de la textura y el punto \\( (-1, -1) \\) es alcanzable en consecuencia. Esto hace posible el manejo de operaciones de rotación.\nLa rotación es una operación mucho más sencilla de ejecutar en coordenadas polares, de modo que sería ideal transformar la actual coordenada \\( (x, y) \\) en \\( (r, \\theta) \\) \\[r = ||(x, y)|| \\\\ \\theta = \\tan^{-1}\\frac{y}{|x|}\\] En este nuevo sistema de coordenadas, para rotar basta con modificar el ángulo, es decir, el punto se transforma a \\( (r, k\\cdot \\theta) \\) después de la operación, siendo \\( k \\) el parámetro que indica cuantose desplaza angularmente el punto.\nComo el sistema lo requiere, es necesario volver a las coordenadas cartesianas, recordando que \\[x = r\\cdot \\cos(\\theta) \\\\ y = r \\cdot \\sin(\\theta)\\] float r = length(coord); float theta = atan(coord.y, abs(coord.x)); theta *= segments; coord = vec2(r * cos(theta), r * sin(theta)); Nótese que los puntos rotarán tanto como segmentos tenga la imagen caleidoscópica deseada.\nFinalmente, se regresa al rango usual de coordenadas, \\( [0, 1] \\) , y el fragmento actual adquiere el color del pixel encontrado en las coordenadas correspondientes.\ncoord = (coord + 1.0) / 2.0; gl_FragColor = texture2D(texture, coord); Referencias # SNAPVALE163, Caleidoscopio "},{"id":9,"href":"/posteffects/docs/Efectos/Ruido/","title":"Ruido","section":"Efectos","content":" Ruido # Los algoritmos de ruido han sido una elegante forma de abordar problemas en distintas áreas, esto se debe a su capacidad para relacionarse con comportamientos caóticos o simplemente aleatorios. Han sido utilizados en la generación de terreno de forma procedural, simulación de físicas de movimiento de fluidos, texturización procedural para obtener materiales más realistas, etc.\nEn esta sección, se hará uso de un algoritmo generador de ruido para causar distorsiones y movimiento en una imagen determinada.\nCódigo del Fragment Shader del efecto: # noise.frag precision mediump float; uniform sampler2D tex; uniform float frequency; uniform float amplitude; uniform float time; uniform float speed; varying vec2 texcoords2; vec3 mod289(vec3 x) { return x - floor(x * (1.0 / 289.0)) * 289.0; } vec4 mod289(vec4 x) { return x - floor(x * (1.0 / 289.0)) * 289.0; } vec4 permute(vec4 x) { return mod289(((x*34.0)+1.0)*x); } vec4 taylorInvSqrt(vec4 r){ return 1.79284291400159 - 0.85373472095314 * r; } float snoise(vec3 v){ const vec2 C = vec2(1.0/6.0, 1.0/3.0) ; const vec4 D = vec4(0.0, 0.5, 1.0, 2.0); vec3 i = floor(v + dot(v, C.yyy) ); vec3 x0 = v - i + dot(i, C.xxx) ; vec3 g = step(x0.yzx, x0.xyz); vec3 l = 1.0 - g; vec3 i1 = min( g.xyz, l.zxy ); vec3 i2 = max( g.xyz, l.zxy ); vec3 x1 = x0 - i1 + C.xxx; vec3 x2 = x0 - i2 + C.yyy; vec3 x3 = x0 - D.yyy; // Permutations i = mod289(i); vec4 p = permute( permute( permute( i.z + vec4(0.0, i1.z, i2.z, 1.0 )) + i.y + vec4(0.0, i1.y, i2.y, 1.0 )) + i.x + vec4(0.0, i1.x, i2.x, 1.0 )); float n_ = 0.142857142857; // 1.0/7.0 vec3 ns = n_ * D.wyz - D.xzx; vec4 j = p - 49.0 * floor(p * ns.z * ns.z); vec4 x_ = floor(j * ns.z); vec4 y_ = floor(j - 7.0 * x_ ); vec4 x = x_ *ns.x + ns.yyyy; vec4 y = y_ *ns.x + ns.yyyy; vec4 h = 1.0 - abs(x) - abs(y); vec4 b0 = vec4( x.xy, y.xy ); vec4 b1 = vec4( x.zw, y.zw ); vec4 s0 = floor(b0)*2.0 + 1.0; vec4 s1 = floor(b1)*2.0 + 1.0; vec4 sh = -step(h, vec4(0.0)); vec4 a0 = b0.xzyw + s0.xzyw*sh.xxyy ; vec4 a1 = b1.xzyw + s1.xzyw*sh.zzww ; vec3 p0 = vec3(a0.xy,h.x); vec3 p1 = vec3(a0.zw,h.y); vec3 p2 = vec3(a1.xy,h.z); vec3 p3 = vec3(a1.zw,h.w); vec4 norm = taylorInvSqrt(vec4(dot(p0,p0), dot(p1,p1), dot(p2, p2), dot(p3,p3))); p0 *= norm.x; p1 *= norm.y; p2 *= norm.z; p3 *= norm.w; vec4 m = max(0.6 - vec4(dot(x0,x0), dot(x1,x1), dot(x2,x2), dot(x3,x3)), 0.0); m = m * m; return 42.0 * dot( m*m, vec4( dot(p0,x0), dot(p1,x1), dot(p2,x2), dot(p3,x3) ) ); } void main() { vec2 texCoords = texcoords2.st + vec2( amplitude * (snoise(vec3(frequency * texcoords2.s, frequency * texcoords2.t, speed * time))), amplitude * (snoise(vec3(frequency * texcoords2.s + 17.0, frequency * texcoords2.t, speed * time))) ); gl_FragColor = texture2D(tex, texCoords); } Lo primero en hacerse es definir ciertas funciones importantes para el desarrollo de este efecto y la mejora de su desempeño. En primer lugar, considerando que glsl no cuenta con una operación de módulo, que se define como: \\[\\mod(x, n) = x - n \\cdot \\lfloor \\frac{x}{n} \\rfloor\\] Se implementa \\( \\mod(\\vec v, 289) \\) para vectores de tres y cuatro dimensiones.\nvec3 mod289(vec3 x) { return x - floor(x * (1.0 / 289.0)) * 289.0; } vec4 mod289(vec4 x) { return x - floor(x * (1.0 / 289.0)) * 289.0; } También se implementa una función para operaciones de permutación, que en este caso se refiere a una operación de hashing que se usará posteriormente. Es\nimportante añadir que es gracias a esta que el ruido adquiere su característico comportamiento seudoaleatorio.\nvec4 permute(vec4 x) { return mod289(((x*34.0)+1.0)*x); } En ocasiones en las que se puede prescindir de la exactitud, es factible usar aproximaciones a funciones conocidas en pos de disminuir el tiempo de ejecución. Una buena forma de obtener estas aproximaciones es el uso de series de Taylor; la que será implementada es:\n\\[\\frac{1}{\\sqrt{x}} \\aprox 1.79284291400159 - 0.85373472095314 \\cdot x\\] vec4 taylorInvSqrt(vec4 r){ return 1.79284291400159 - 0.85373472095314 * r; } Ruido Simplex. # La función más importante de este efecto se conoce como Ruido Simplex, una mejora considerable sobre el Ruido de Perlin en términos de eficiencia computacional. Una de sus ventajas es la versatilidad que demuestra al poder ser implementada para cualquier dimensión, en este caso se usarán tres.\nfloat snoise(vec3 v){ ... } Conforme se hagan acercamientos a diferentes fragmentos de esta función, se darán algunas generalidades del funcionamiento de este algoritmo. En primer lugar, se definen algunas constantes vitales para el resto de los cálculos.\nconst vec2 C = vec2(1.0/6.0, 1.0/3.0) ; const vec4 D = vec4(0.0, 0.5, 1.0, 2.0); La segunda componente de C, que es el factor que determina la distancia entre el baricentro de un triángulo y el lado que su mediana interseca, funge como factor de sesgo; la primera componente ayudará a deshacer dicha transformación.\nEl algoritmo supone una malla de tetraedros irregulares abarcando el espacio y, por tanto, conteniendo los puntos de interés. Para mayor entendimiento, de momento es menester hacerse de una imagen geométrica de cada paso.\nvec3 i = floor(v + dot(v, C.yyy) ); vec3 x0 = v - i + dot(i, C.xxx) ; Como el punto actual (v) se encuentra en uno de los 24 tetraedros que llenan el espacio, es importante saber cual lo contiene, y una buena forma de empezar es hallar una esquina inicial.\nPara alinear la malla con los ejes espaciales, se hace una transformación de sesgo sobre el mundo y extrayendo las partes enteras de cada componente del vector vtransformado es posible determinar en qué tetraedro se encuentra. Basta con deshacer el sesgado y restar ese antiguo indicador de ubicación a v para hallar elorigen deseado (x0).\nAhora se debe encontrar el resto de los vértices\nvec3 g = step(x0.yzx, x0.xyz); vec3 l = 1.0 - g; vec3 i1 = min( g.xyz, l.zxy ); vec3 i2 = max( g.xyz, l.zxy ); vec3 x1 = x0 - i1 + C.xxx; vec3 x2 = x0 - i2 + C.yyy; // 2.0*C.x = 1/3 = C.y vec3 x3 = x0 - D.yyy; // -1.0+3.0*C.x = -0.5 = -D.y Las funciones de paso son una buena forma de comparar los vectores y determinar cuales son los puntos más cercanos al origen del tetraedro para hallar los vértices de forma ordenada.\nSe realiza una serie de permutaciones concatenadas sobre sumas de las componentes del vector i\ni = mod289(i); vec4 p = permute( permute( permute( i.z + vec4(0.0, i1.z, i2.z, 1.0 )) + i.y + vec4(0.0, i1.y, i2.y, 1.0 )) + i.x + vec4(0.0, i1.x, i2.x, 1.0 )); Este vector p contiene ahora valores seudo aleatorios con los que se podrá acceder posteriormente a los gradientes y que además garantizan que los patrones formados por el ruido no sean repetitivos.\nGracias a la constante D se define un vector de normalización que servirá para calcular las coordenadas de los vértices y sus gradientes después de haber pasado por la permutación.\nfloat n_ = 0.142857142857; // 1.0/7.0 vec3 ns = n_ * D.wyz - D.xzx; vec4 j = p - 49.0 * floor(p * ns.z * ns.z); vec4 x_ = floor(j * ns.z); vec4 y_ = floor(j - 7.0 * x_ ); vec4 x = x_ *ns.x + ns.yyyy; vec4 y = y_ *ns.x + ns.yyyy; vec4 h = 1.0 - abs(x) - abs(y); vec4 b0 = vec4( x.xy, y.xy ); vec4 b1 = vec4( x.zw, y.zw ); vec4 s0 = floor(b0)*2.0 + 1.0; vec4 s1 = floor(b1)*2.0 + 1.0; vec4 sh = -step(h, vec4(0.0)); vec4 a0 = b0.xzyw + s0.xzyw*sh.xxyy ; vec4 a1 = b1.xzyw + s1.xzyw*sh.zzww ; vec3 p0 = vec3(a0.xy,h.x); vec3 p1 = vec3(a0.zw,h.y); vec3 p2 = vec3(a1.xy,h.z); vec3 p3 = vec3(a1.zw,h.w); Luego de haber obtenido los gradientes, estos deben ser normalizados y mezclados.\nvec4 norm = taylorInvSqrt(vec4(dot(p0,p0), dot(p1,p1), dot(p2, p2), dot(p3,p3))); p0 *= norm.x; p1 *= norm.y; p2 *= norm.z; p3 *= norm.w; vec4 m = max(0.6 - vec4(dot(x0,x0), dot(x1,x1), dot(x2,x2), dot(x3,x3)), 0.0); m = m * m; Finalmente, se calcula el efecto de dichos gradientes sobre el punto de entrada y se retorna como resultado de la función.\nreturn 42.0 * dot( m*m, vec4( dot(p0,x0), dot(p1,x1), dot(p2,x2), dot(p3,x3) ) ); Función Principal # Una vez desarrollado el algoritmo de ruido simplex, queda hacer uso de él y aplicarl, en este caso sobre los colores de la escena. La textura se muestrea de modo que la amplitud, frecuencia y velocidad alteren la forma de las oscilaciones del ruido, que también dependerá principalmente del tiempo (en milisegundos) transcurrido desde la ejecución del programa.\nvoid main() { vec2 texCoords = texcoords2.st + vec2( amplitude * (snoise(vec3(frequency * texcoords2.s, frequency * texcoords2.t, speed * time))), amplitude * (snoise(vec3(frequency * texcoords2.s + 17.0, frequency * texcoords2.t, speed * time))) ); gl_FragColor = texture2D(tex, texCoords); } Referencias: # Zapata. F, Utilizando Algoritmos Generadores de Ruido. Gustavson. S, Simplex noise demystified Gonzalez. P, GLSL Noise Algorithms "},{"id":10,"href":"/posteffects/docs/Efectos/Rayos/","title":"Rayos","section":"Efectos","content":" Rayos # Código del Fragment Shader del efecto: # Cotidianamente no hay entornos uniformemente iluminados, la luz interactúa con los objetos de formas distintas considerando factores como su posición respecto al emisor y al observador, las propiedades intrínsecas de la onda y el material sobre el que cae. Es de este hecho que surge una de las principales aplicaciones de los shaders, los modelos de iluminación.\nCon intensión de dar más realismo o vida a una escena, se aplican los modelos de iluminación. Estos simulan el comportamiento tanto de los emisores de luz, como de los materiales alumbrados en términos de opacidad y reflectancia. La iluminación es inherente a la escena, por lo que estos modelos no pueden considerarse como un efecto de posprocesado, sin embargo eso no impide realizar un efecto capaz de dotar a los objetos de haces fulgurantes.\nLa siguiente escena muestra un conjunto de objetos capaces de irradiar luz, dirigida por la posición del puntero del mouse sobre el sector izquierdo del sketch (que muestra el modelo previo a la aplicación del efecto) hacia la pantalla.\nrays.frag precision mediump float; uniform sampler2D rtex; uniform sampler2D otex; uniform vec2 lightPositionOnScreen; uniform float lightDirDOTviewDir; varying vec2 texcoords2; const int NUM_SAMPLES = 255; void main(void){ vec4 origColor = texture2D(otex, texcoords2.st); vec4 raysColor = texture2D(rtex, texcoords2.st); if (lightDirDOTviewDir\u0026gt;0.0){ float exposure = 0.5/float(NUM_SAMPLES); float decay = 1.0; float density\t= 1.25; float weight\t= 6.0; float illuminationDecay = 1.0; vec2 deltaTextCoord = vec2( texcoords2.st - lightPositionOnScreen); deltaTextCoord *= 1.0 / float(NUM_SAMPLES) * density; vec2 textCoo = texcoords2.st; for(int i=0; i \u0026lt; NUM_SAMPLES ; i++){ textCoo -= deltaTextCoord; vec4 tsample = texture2D(rtex, textCoo ); tsample *= illuminationDecay * weight; raysColor += tsample; illuminationDecay *= decay; } raysColor *= exposure * lightDirDOTviewDir; float p = 0.3 *raysColor.g + 0.59*raysColor.r + 0.11*raysColor.b; gl_FragColor = origColor + p; } else { gl_FragColor = origColor; } } La clave para comprender el funcionamiento de este efecto se encuentra principalmente en este fragmento:\nSe le envía al shader dos veces la textura correspondiente al buffer que contiene la escena principal.\nrays_shader.setUniform(\u0026#39;otex\u0026#39;, main_pg); rays_shader.setUniform(\u0026#39;rtex\u0026#39;, main_pg); En el fragment shader Se indica el color actual del fragmento y del rayo que este emitirá, en este caso son idénticos, pero existe la posibilidad de que la luz proyectada esté dada por cualquier otra imagen enviada usando una textura.\nvec4 origColor = texture2D(otex, texcoords2.st); vec4 raysColor = texture2D(rtex, texcoords2.st); En los modelos de iluminación, la cantidad de luz que incide sobre un objeto está dada en gran parte por el producto punto entre la normal de la superficie y la dirección a la fuente de luz, tal es el caso en la reflexión difusa: \\[I_d = kL_d (N \\cdot L_d)\\] De este modo, la variable lightDirDOTviewDir se explica al establecer un paralelismo entre la normal de una superficie y la dirección de la cámara. La intensidad de los rayos que lleguen a la pantalla estará dependerá en gran medida de cuán alineados estén los vectores de vista y dirección de la luz (que es emitida por los objetos de la escena).\nRecuerde que si el producto punto es 0 no hay relación entre los vectores, y si es negativo la luz no llega a la cámara porque su dirección es opuesta.\nif (lightDirDOTviewDir \u0026gt; 0.0){ ... } else { gl_FragColor = origColor; } En caso de que los vectores tengan una relación aceptable es necesario definir las variables que dictarán el comportamiento de la luz. La exposición exposure influye en la intensidad del efecto y es importante notar que está normalizada por la cantidad de muestras. El decaimiento decay determina la disminusión de la intensidad de luz en relación a la distancia. La densidad density determina cuántas muestras se toman por pixel. El peso weight indica cuanto contribuye cada muestra a la intensidad de la luz resultante. Por último, el decaimiento de iluminación iluminationDecay controla cuánto cambia la intensidad de la luz en cada muestra individual.\nfloat exposure = 0.5/float(NUM_SAMPLES); float decay = 1.0; float density\t= 1.25; float weight\t= 6.0; float illuminationDecay = 1.0; Una muestra es una proyección de la textura de rayo cuyo color se modifica según los parámetros previamente expuestos. Cada muestra simula estar a mayor distancia de la pantalla que la anterior y presenta un corrimiento en su centro. Conforme la muestra tenga mayores valores, los centros tenderán al centro de la textura original partiendo de la posición de luz en pantalla.\nFigura 1: 2 muestras Figura 2: 3 muestras Figura 3: 4 muestras De esto se deduce que un rayo no es más que una pila de muestras atenuadas cuidadosamente según su posición respecto a la pantalla y que su efecto iluminador se debe entonces a la suma de sus colores individuales.\nvec2 deltaTextCoord = vec2( texcoords2.st - lightPositionOnScreen); deltaTextCoord *= 1.0 / float(NUM_SAMPLES) * density; vec2 textCoo = texcoords2.st; for(int i=0; i \u0026lt; NUM_SAMPLES ; i++){ textCoo -= deltaTextCoord; vec4 tsample = texture2D(rtex, textCoo ); tsample *= illuminationDecay * weight; raysColor += tsample; illuminationDecay *= decay; } Finalmente, la exposición de la luz se aplica, se calcula la intensidad del color de los rayos y se suma al color del fragmento actual.\nraysColor *= exposure * lightDirDOTviewDir; float p = 0.3 *raysColor.g + 0.59*raysColor.r + 0.11*raysColor.b; gl_FragColor = origColor + p; Referencias # Institute of New Imaging Technologies, Universitat Jaume I, Tema 5: Modelos de Iluminación y Sombreado, Síntesis de Imágen y Animación "}]